{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add, Flatten, Lambda, Reshape, BatchNormalization, concatenate, AveragePooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, MeanSquaredError, RootMeanSquaredError, Mean, binary_crossentropy, binary_accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Using local GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "\n",
    "if in_colab:\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    except ValueError:\n",
    "        if 'GPU' in [gpu[-1] for gpu in tf.config.list_physical_devices('GPU')]:\n",
    "            print('Running on Google Colab GPU')\n",
    "        else:\n",
    "            print('Not connected to a TPU or GPU runtime')\n",
    "\n",
    "else:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(physical_devices)\n",
    "    try:\n",
    "        if len(physical_devices):\n",
    "            for gpu in physical_devices:\n",
    "                tf.config.experimental.set_memory_growth(gpu, enable = True)\n",
    "                print(f\"Using local GPU: {gpu}\")\n",
    "            sess = tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(log_device_placement = True))\n",
    "        else:\n",
    "            print(\"No local GPU found\")\n",
    "    except:\n",
    "        print(\"Error Mounting a GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, model_name, inception_outputs=None):\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    if inception_outputs:\n",
    "        for out in inception_outputs:\n",
    "            plt.plot(history.history[f'{out}_loss'], label='Training Loss')\n",
    "            plt.plot(history.history[f'val_{out}_loss'], label='Validation Loss')\n",
    "            plt.title(f'Training and Validation Loss {model_name} {out}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history, model_name, inception_outputs=None):\n",
    "    # Plot training and validation accuracy\n",
    "    if inception_outputs:\n",
    "        for out in inception_outputs:\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            plt.subplot(3, 1, 1)\n",
    "                \n",
    "            plt.plot(history.history[f'{out}_accuracy'], label=f'{out} training Accuracy')\n",
    "            plt.plot(history.history[f'val_{out}_accuracy'], label=f'{out} validation Accuracy')\n",
    "            plt.title(f'Training and Validation Accuracy {model_name} {out}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "\n",
    "            # Plot training and validation MAE\n",
    "            plt.subplot(3, 1, 2)\n",
    "            plt.plot(history.history[f'{out}_mae'], label='Training MAE')\n",
    "            plt.plot(history.history[f'val_{out}_mae'], label='Validation MAE')\n",
    "            plt.title(f'Training and Validation MAE {model_name} {out}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.legend()\n",
    "\n",
    "            # Plot training and validation RMSE\n",
    "            plt.subplot(3, 1, 3)\n",
    "            plt.plot(history.history[f'{out}_rmse'], label='Training RMSE')\n",
    "            plt.plot(history.history[f'val_{out}_rmse'], label='Validation RMSE')\n",
    "            plt.title(f'Training and Validation RMSE {model_name} {out}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.subplot(3, 1, 1)\n",
    "\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "        plt.title(f'Training and Validation Accuracy {model_name}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot training and validation MAE\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.plot(history.history['mae'], label='Training MAE')\n",
    "        plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "        plt.title(f'Training and Validation MAE {model_name}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot training and validation RMSE\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.plot(history.history['rmse'], label='Training RMSE')\n",
    "        plt.plot(history.history['val_rmse'], label='Validation RMSE')\n",
    "        plt.title(f'Training and Validation RMSE {model_name}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, generator, num_examples=5, seed=42, size=(12, 4)):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for _ in range(num_examples):\n",
    "        x_sample, y_sample = next(generator)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(x_sample, verbose=False)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=size)\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(x_sample[0], cmap='gray')\n",
    "        plt.title('Original')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(y_sample[0], cmap='gray')\n",
    "        plt.title('Expected')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(y_pred[0], cmap='gray')\n",
    "        plt.title('Reconstructed by Model')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_many_outputs(model, generator, num_examples=5, seed=42, size=(16, 4)):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    for _ in range(num_examples):\n",
    "        x_sample, y_sample = next(generator)\n",
    "\n",
    "        # Predict\n",
    "        y_preds = model.predict(x_sample, verbose=False)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=size)\n",
    "\n",
    "        # Plot original input\n",
    "        plt.subplot(1, len(y_preds) + 2, 1)\n",
    "        plt.imshow(x_sample[0], cmap='gray')\n",
    "        plt.title('Original')\n",
    "\n",
    "        # Plot ground truth\n",
    "        plt.subplot(1, len(y_preds) + 2, 2)\n",
    "        plt.imshow(y_sample[0], cmap='gray')\n",
    "        plt.title('Expected')\n",
    "\n",
    "        # Plot model predictions\n",
    "        for j, y_pred in enumerate(y_preds):\n",
    "            plt.subplot(1, len(y_preds) + 2, j + 3)\n",
    "            plt.imshow(y_pred[0], cmap='gray')\n",
    "            plt.title(f'Reconstructed by Model (Output {j + 1})')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "seed = 42\n",
    "\n",
    "INPUT_SHAPE = (400, 600, 3)\n",
    "IMAGE_SHAPE = (400, 600)\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3009 validated image filenames.\n",
      "Found 3009 validated image filenames.\n",
      "Found 376 validated image filenames.\n",
      "Found 376 validated image filenames.\n",
      "Found 377 validated image filenames.\n",
      "Found 377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "base_directory = 'Data'\n",
    "hires_folder = os.path.join(base_directory, 'high res')\n",
    "lowres_folder = os.path.join(base_directory, 'low res')\n",
    "\n",
    "data = pd.read_csv(\"Data/image_data.csv\")\n",
    "data['low_res'] = data['low_res'].apply(lambda x: os.path.join(lowres_folder, x))\n",
    "data['high_res'] = data['high_res'].apply(lambda x: os.path.join(hires_folder, x))\n",
    "#data.head()\n",
    "\n",
    "# data = filter_df(data, viable_nums=[\"6\"]) # For GAN\n",
    "\n",
    "train_data, val_test_data = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=seed)\n",
    "\n",
    "image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_hiresimage_generator = image_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='high_res',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "train_lowresimage_generator = image_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    x_col='low_res',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "val_hiresimage_generator = image_datagen.flow_from_dataframe(\n",
    "    val_data,\n",
    "    x_col='high_res',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "val_lowresimage_generator = image_datagen.flow_from_dataframe(\n",
    "    val_data,\n",
    "    x_col='low_res',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "test_hiresimage_generator = image_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    x_col='high_res',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "test_lowresimage_generator = image_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    x_col='low_res',\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    class_mode=None,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "train_generator = zip(train_lowresimage_generator, train_hiresimage_generator)\n",
    "val_generator = zip(val_lowresimage_generator, val_hiresimage_generator)\n",
    "test_generator = zip(test_lowresimage_generator, test_hiresimage_generator)\n",
    "\n",
    "def imageGenerator(generator):\n",
    "    for (low_res, hi_res) in generator:\n",
    "        yield (low_res, hi_res)\n",
    "\n",
    "train_samples = train_hiresimage_generator.samples\n",
    "val_samples = val_hiresimage_generator.samples\n",
    "\n",
    "train_img_gen = imageGenerator(train_generator)\n",
    "val_img_gen = imageGenerator(val_generator)\n",
    "test_img_gen = imageGenerator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.image.ssim(y_true, y_pred, max_val=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_u_net(input_shape=INPUT_SHAPE):\n",
    "    # Input layer\n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(16, (3, 3), padding='same', activation='relu')(input_img)\n",
    "    conv2 = Conv2D(16, (3, 3), padding='same', activation='relu')(conv1)\n",
    "    maxpool1 = MaxPooling2D()(conv2)\n",
    "\n",
    "    conv3 = Conv2D(32, (3, 3), padding='same', activation='relu')(maxpool1)\n",
    "    conv4 = Conv2D(32, (3, 3), padding='same', activation='relu')(conv3)\n",
    "    maxpool2 = MaxPooling2D()(conv4)\n",
    "\n",
    "    conv5 = Conv2D(64, (3, 3), padding='same', activation='relu')(maxpool2)\n",
    "    conv6 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv5)\n",
    "\n",
    "    # Bottleneck\n",
    "    bottleneck = Conv2D(64, (3, 3), padding='same', activation='relu')(conv6)\n",
    "    maxpool3 = MaxPooling2D(pool_size=(2, 2))(bottleneck)\n",
    "\n",
    "    # Decoder\n",
    "    upsample1 = UpSampling2D()(maxpool3)\n",
    "    concat1 = concatenate([upsample1, conv5], axis=-1)\n",
    "    conv7 = Conv2D(64, (3, 3), padding='same', activation='relu')(concat1)\n",
    "    conv8 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv7)\n",
    "\n",
    "    upsample2 = UpSampling2D()(conv8)\n",
    "    concat2 = concatenate([upsample2, conv3], axis=-1)\n",
    "    conv9 = Conv2D(32, (3, 3), padding='same', activation='relu')(concat2)\n",
    "    conv10 = Conv2D(32, (3, 3), padding='same', activation='relu')(conv9)\n",
    "\n",
    "    upsample3 = UpSampling2D()(conv10)\n",
    "    concat3 = concatenate([upsample3, conv1], axis=-1)\n",
    "    conv11 = Conv2D(16, (3, 3), padding='same', activation='relu')(concat3)\n",
    "    conv12 = Conv2D(16, (3, 3), padding='same', activation='relu')(conv11)\n",
    "\n",
    "    # Output layer\n",
    "    output_img = Conv2D(3, (3, 3), padding='same', activation='sigmoid')(conv12)\n",
    "\n",
    "    unet = Model(input_img, output_img)    \n",
    "    metrics_list = ['accuracy', ssim_loss, MeanAbsoluteError(name='mae'), RootMeanSquaredError(name='rmse')]\n",
    "    unet.compile(optimizer='adam', loss=ssim_loss, metrics=metrics_list)\n",
    "    \n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet = build_u_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 72/376 [====>.........................] - ETA: 1:51 - loss: 0.3574 - accuracy: 0.4240 - ssim_loss: 0.3574 - mae: 0.1521 - rmse: 0.2033"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "history = Unet.fit(\n",
    "    train_img_gen,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    steps_per_epoch=train_samples//BATCH_SIZE,\n",
    "    validation_data = val_img_gen,\n",
    "    validation_steps=val_samples//BATCH_SIZE,\n",
    "    callbacks=[early_stopping, reduce_lr_plateau]\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "model_name = \"Unet\"\n",
    "time_dict = {model_name: training_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet.save(\"models/trained_unet_alt_loss.h5\")\n",
    "# print(f\"Model size: {os.stat('models/trained_unet_alt_loss.h5').st_size / 1024} kB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, \"Unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, \"Unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(Unet,train_img_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(Unet, test_img_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
